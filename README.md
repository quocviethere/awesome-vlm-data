# Awesome VLM Data [![Awesome](https://awesome.re/badge.svg)](https://awesome.re)

This is the repository corresponding with the blog post on data-centric analysis for Vision-Language Models.

## Synthetic captions

1. **Li et al.** (2022). *BLIP: Bootstrapping Language-Image Pre-training for Unified Vision-Language Understanding and Generation*. In *ICML*, 12888–12900. [PDF](https://arxiv.org/pdf/2201.12086.pdf)

2. **Li et al.** (2024). *What If We Recaption Billions of Web Images with LLaMA-3?* In *arXiv*.

3. **Sharifzadeh et al.** (2024). *Synth$^2$: Boosting Visual-Language Models with Synthetic Captions and Image Embeddings*. In *arXiv*.

4. **Liu et al.** (2024). *CLIPS: An Enhanced CLIP Framework for Learning with Synthetic Captions*. In *arXiv*.

5. **Yang et al.** (2023). *ALIP: Adaptive Language-Image Pre-training with Synthetic Caption*. In *ICCV*, 2910–2919. [PDF](https://arxiv.org/pdf/2310.07699.pdf)

6. **Fang et al.** (2024). *VILA$^2$: VILA Augmented VILA*. In *arXiv*.

7. **Fan et al.** (2023). *Improving CLIP Training with Language Rewrites*. In *NeurIPS*.

8. **Hammoud et al.** (2024). *SynthCLIP: Are We Ready for a Fully Synthetic CLIP Training?* In *CVPR 2024 Synthetic Data for Computer Vision Workshop*. [PDF](https://arxiv.org/pdf/2402.01832.pdf)

9. **Lai et al.** (n.d.). *From Scarcity to Efficiency: Improving CLIP Training via Visual-enriched Captions*.

10. **Lai et al.** (2025). *VeCLIP: Improving CLIP Training via Visual-Enriched Captions*. In *Lecture Notes in Computer Science*, 111–127. [PDF](https://arxiv.org/pdf/2310.07699.pdf)

11. **Nguyen et al.** (2023). *Improving Multimodal Datasets with Image Captioning*. In *NeurIPS*.

12. **Rotstein et al.** (2024). *FuseCap: Leveraging Large Language Models for Enriched Fused Image Captions*. In *WACV*, 5677–5688. [PDF](https://arxiv.org/pdf/2402.01832.pdf)

13. **Santurkar et al.** (2023). *Is a Caption Worth a Thousand Images? A Study on Representation Learning*. In *ICLR*.

14. **Yu et al.** (2024). *CapsFusion: Rethinking Image-Text Data at Scale*. In *CVPR*.

15. **Zhu et al.** (2024). *ChatGPT Asks, BLIP-2 Answers: Automatic Questioning Towards Enriched Visual Descriptions*. In *TMLR*. [PDF](https://arxiv.org/pdf/2303.06594.pdf)

